# Tutorial 4: Exportaci贸n de Modelos a ONNX

## 驴Qu茅 es ONNX?
**ONNX (Open Neural Network Exchange)** es un formato est谩ndar abierto para representar modelos de Machine Learning. NumRs soporta la exportaci贸n nativa a ONNX, lo que significa que puedes entrenar tu modelo en Rust y desplegarlo en cualquier entorno (Python, C++, Web, Edge Devices) que soporte ONNX Runtime.

## C贸mo funciona en NumRs
La exportaci贸n en NumRs funciona mediante **Tracing** (Rastreo), similar a `torch.jit.trace`.

###  PyTorch vs NumRs: Exportaci贸n
| Concepto    | PyTorch                                  | NumRs                                                                                      |
| ----------- | ---------------------------------------- | ------------------------------------------------------------------------------------------ |
| **Funci贸n** | `torch.onnx.export(model, args, path)`   | `numrs::ops::export::export_to_onnx(&tensor, path)`                                        |
| **Input**   | Tupla de argumentos `(x, y)`             | Tensor "final" del grafo computacional                                                     |
| **Alcance** | Exporta la ejecuci贸n completa del modelo | Exporta **el grafo que gener贸 el tensor**, ya sea un modelo entero o una operaci贸n simple. |

> [!NOTE]
> **Exportaci贸n de Tensores Puros**: No necesitas un `Module` para exportar. Si calculas `let z = x.add(&y)?`, puedes llamar a `export_to_onnx(&z, ...)` y obtendr谩s un archivo ONNX v谩lido que contiene solo esa suma. Esto es 煤til para utilidades o pre-procesamiento.

## Ejemplo de Exportaci贸n

Tomemos el modelo `ForecastCNN` de los tutoriales anteriores. Una vez entrenado, el proceso de exportaci贸n es el siguiente:

### 1. Preparar un Input Dummy
El input debe tener la misma forma (shape) que los datos reales, pero no necesita tener valores significativos.

**Importante**: Los inputs del grafo deben tener `requires_grad = false`. Si tienen `true`, el exportador podr铆a confundirlos con pesos entrenables.

```rust
use numrs::autograd::Tensor;
use numrs::Array;

// Input dummy: [Batch=1, SeqLen=128]
// Nota: Backends como WebGPU requieren shapes consistentes.
let dummy_data = Array::zeros(vec![1, 128]); 
let input_tensor = Tensor::new(dummy_data, false); // requires_grad = false
```

### 2. Ejecutar un Forward Pass
El modelo debe estar en modo evaluaci贸n (`eval()`) si usas BatchNorm o Dropout, para asegurar un comportamiento determinista.

```rust
// Asegurar modo evaluaci贸n
model.eval();

// Ejecutar forward para trazar el grafo
let output = model.forward(&input_tensor)?;
```

### 3. Llamar a `export_to_onnx`
La funci贸n toma el tensor de salida final y recorre el grafo hacia atr谩s hasta los inputs.

```rust
use numrs::ops::export::export_to_onnx;

let path = "forecast_cnn.onnx.json"; // NumRs usa un formato JSON-friendly intermedio actualmente
export_to_onnx(&output, path)?;

println!("Modelo exportado a {}", path);
```

## Consideraciones Avanzadas

### Batch Normalization & Running Stats
NumRs maneja autom谩ticamente los estados internos (`running_mean`, `running_var`) de BatchNorm. Estos se exportan como inputs adicionales al nodo ONNX pero marcados como pesos fijos (Initializers), por lo que el usuario final no necesita proveerlos manualmente.

### Dynamic Shapes
Actualmente, NumRs exporta grafos con formas est谩ticas basadas en el `dummy_input`. Si necesitas formas din谩micas, aseg煤rate de que el runtime de inferencia soporte redimensionamiento, o exporta versiones para cada tama帽o esperado.

## Siguiente Paso
Una vez tengas tu archivo `.onnx.json`, puedes cargarlo para inferencia usando NumRs (Tutorial 05) o cualquier otro runtime compatible.
